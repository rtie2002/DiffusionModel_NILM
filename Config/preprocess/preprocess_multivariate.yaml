# ====================================================================================================
# PART 1: UK-DALE PREPROCESSING & NORMALIZATION
# ====================================================================================================
# Files using this section:
#   - preprocess_NILMformer\multivariate_ukdale_preprocess_training+validating.py
#   - preprocess_NILMformer\multivariate_ukdale_preprocess_testing.py
# Purpose: Defines paths, global normalization stats (Z-score), and data splitting rules.

paths:
  data_dir: "UK_DALE/"
  save_path: "created_data/UK_DALE/"
  synthetic_dir: "synthetic_data_multivariate"

normalization:
  aggregate_mean: 522      # Mean for cleaning/normalizing aggregate (mains) channel
  aggregate_std: 814       # Std Dev for cleaning/normalizing aggregate (mains) channel

processing:
  sample_seconds: 6       # Sampling rate (resamples raw 6s data to 1 min)
  
  # Settings for multivariate_ukdale_preprocess_training+validating.py
  training:
    validation_percent: 20  # Percentage of data to use for validation (split from tail)
    testing_percent: 20     # Percentage of data to use for testing (usually 0 for training script)

  # Settings for multivariate_ukdale_preprocess_testing.py
  testing:
    validation_percent: 0  # Typically 0 for testing script
    testing_percent: 0   # Use 100% of the loaded data for generating test set


# ====================================================================================================
# PART 2: APPLIANCE DEFINITIONS (Houses, Channels, Stats)
# ====================================================================================================
# Files using this section:
#   - preprocess_NILMformer\multivariate_ukdale_preprocess_*.py (train/test splits, Z-score mean/std)
#   - Data_filtering\algorithm1_v2_multivariate.py (on_power_threshold, max_power)
# Purpose: Defines which houses/channels belong to which set, and appliance-specific stats.

appliances:
  kettle:
    mean: 700                    # Mean power consumption for Z-score normalization
    std: 1000                    # Standard deviation for Z-score normalization
    max_power: 3998              # Max power for MinMax normalization (used in Algorithm 1)
    on_power_threshold: 200      # Threshold to consider appliance ON (used in Algorithm 1)
    real_max_power: 3998         # Real maximum power observed in dataset (Watts)
    max_power_clip: 3998         # Clipped maximum for filtering algorithms (Watts)
    train:
      houses: [1, 3, 5]
      channels: [10, 2, 18]
    test:
      houses: [2]
      channels: [8]

  microwave:
    mean: 500
    std: 800
    max_power: 3969              # Updated to match real_max_power
    on_power_threshold: 200
    real_max_power: 3969
    max_power_clip: 3969
    train:
      houses: [1, 5]
      channels: [13, 23]
    test:
      houses: [2]
      channels: [15]

  fridge:
    mean: 200
    std: 400
    max_power: 350
    on_power_threshold: 50
    real_max_power: 3323
    max_power_clip: 300       # Clipped max for filtering, as per original config
    train:
      houses: [1, 5]
      channels: [12, 19]
    test:
      houses: [2]
      channels: [14]

  dishwasher:
    mean: 700
    std: 1000
    max_power: 3964
    on_power_threshold: 10
    real_max_power: 3964
    max_power_clip: 3964
    train:
      houses: [1, 5]
      channels: [6, 22]
    test:
      houses: [2]
      channels: [13]

  washingmachine:
    mean: 400
    std: 700
    max_power: 3999
    on_power_threshold: 20
    real_max_power: 3999
    max_power_clip: 3999
    train:
      houses: [1, 5]
      channels: [5, 24]
    test:
      houses: [2]
      channels: [12]


# ====================================================================================================
# PART 3: ALGORITHM 1 (Data Filtering & Selection)
# ====================================================================================================
# Files using this section:
#   - Data_filtering\algorithm1_v2_multivariate.py
# Purpose: Parameters for selecting "effective" windows of data used to train the Diffusion Model.

algorithm1:
  window_length: 10          # Number of samples to keep BEFORE and AFTER an event
  remove_spikes: true        # Enable/Disable pre-cleaning of isolated spikes
  spike_window: 5            # Window size for detecting spikes
  spike_threshold: 3.0       # Multiplier (value > 3.0 * median = spike)
  background_threshold: 50   # Threshold below which signal is considered noise/off (Watts)
  clip_max: null             # (Optional) Hard cap on power values before normalization
  x_noise: 0                 # Zero out any values below this absolute floor


# ====================================================================================================
# PART 4: DATA MIXING (Synthetic Data Generation Windowing)
# ====================================================================================================
# Files using this section:
#   - mix_training_data_multivariate.py
# Purpose: Controls how the processed data sequences are chopped and shuffled for training.

mixing:
  window_size: 100      # Sequence length / Window size for shuffling. Matches mix_training_data_multivariate.py
  shuffle: False          # Randomly shuffle the order of windows before saving to CSV?
  time_cols:             # Time features to include/preserve
    - 'minute_sin'
    - 'minute_cos'
    - 'hour_sin'
    - 'hour_cos'
    - 'dow_sin'
    - 'dow_cos'
    - 'month_sin'
    - 'month_cos'
